# MetTag LARRY Barcode Tracing for Ovarian Cancer

<img src="/assets/images/Logo_OVA.png" width="180" height="220"/>

This is a sub-repo for under MetTag project. We keep the ovarian cancer MetTag tracing data analysis here. The overall data analysis pipeline is similar to MetTag LARRY lung metastasis data, with some minor optimization of reprocessing and barcodes calling along with other improvements.

## 1. Experimental design

### - Ovarian cancer metastasis model

For ovarian mets model, omentums and lavage/ascital fluid were obtained from 2-3 month old female C57Bl/6 mice with OvCa metastases. Omental metastases were established by repeated injection of 400K cell/dose (6x times) of barcoded ID8 p53-/- cells over 12 days, followed by 4 weeks of tumor outgrowth time. Cell suspensions from omentums were prepared by mechanical dissociation, followed by enyzmatic digestion using collagenase and DNAse. The single cell suspension was then sorted for ZombieRed negative live cells. For ascital fluid, RBC lysis was performed along with several 1xPBS washes. Then, we stained each sample with it's own unique hashing antibody so that we could subsequently pool the samples for loading onto two lanes on the 10x Chromium machine and later prepare 2x three libraries consisting of those samples. 3x libraries from each lane are sequenced separately on a NovaSeq X platform. The detailed experiment summary can be found [here](/assets/UTSW02_Lib_Info.pptx).

### - 10X library generation

10X sequencing library was prepared using 10X 3'RNA assay based on 10x standard protocol. MetTag BC contains a 10X CS1 sequence. It was captured in a similar fasion as gRNA by following 10X 3' feature barcode librarie's manual. The final sequencing-ready pooled library contains: 1) Transcriptome; 2) HTO hash tagging (CITE-seq); 3) feature barcoding library (MagTag-BC). NOTE: For MetTag BC, a smallRNA library PCR handle was used similar to ADT library in CITE-seq experiment. The final structure of LARRY sequencing library can be found [here](https://benchling.com/s/seq-aYnci9wcYZekU8R0pSEd?m=slm-DvL7sU0iihS2EGApoua8).

## 2. Single cell sequencing and 10X cellranger processing

### - Single cell sequencing information and RAW data location on Box

1.  [UTSW_DATA/R02_EA/RAW](https://utsw.box.com/s/mhr58y4ta63hdzrj9nzja9swgbc7md91)

2.  [UTSW_DATA/R02_EA/Subinfo_UTSW_CITE_R02](https://utsw.box.com/s/fn5bi0x205fadkedqfc1lzmxhuuoxwwt)

    L1: omentum sample (Om); L2: Ascites (Asc) sample

### - MetTag BC handling

#### Simple way - A quick check of LARRY reads structure

Under Linux bash environment, we use grep command the extract unique LARRY BC and assembled a BC whitelist, which can give a quick sense the sequencing reads quality.

For a quick check of Lib_ID distribution, we can also grep out the Lib_IDs reads and count line numbers. For detailed code, refer to [here](/Code/Old_code/00_LARRY_whitelist_Lib_ID.sh).

**NOTE:** The whitelist generated by this method covers a much larger number of LARRY BC than the "alternative" method below, as it did not consider the background noise reads.

#### Better way - CellBC-UMI-LibID-LARRY extraction and kneeplot based method to generate LARRY whitelist and Lib-ID distributions

**NOTE:** To obtain high sequencing depth of LARRY BC, the same LARRY lib (L1 and L2) were sequenced twice (R2_EA and UTSW09). Then the fastq files were concatenated and saved under Box: [R02_EA/RAW/LARRY/Combined_LARRY_R02_UTSW09/Combined_LARRY](https://utsw.box.com/s/yrhbboz9rdpvata2v5mbxqo8zhgepp1w)

LARRY and LibID reads will not be barcode corrected during the 10X cellranger run. We filter and extract high quality reads with CellBC, UMI, LARRY, Lib_ID directly. We use knee density method to identify likely true cell barcode and LARRY barcodes. Then we correct potential sequencing errors (e.g. Ns) of CellBC, Lib_ID, and LARRY based on hamming distance threshold. Finally, we generate sparse count matrix of Lib_ID and LARRY by collapsing UMIs. For each step, refer to the following:

Step 1. [01_DirectLARRY_extract](/Code/01_DirectLARRY_extract_L1.sh): This bash script will do the following

1.  Extract cellBC, UMI, Lib-ID, LARRY.
2.  Filter out NA and long stretch of A/C/C/G from extracted table. "extracted_cellBC_UMI_LibIDs_LARRY_filtered.txt" will be used as input for barcode correction script: 03_correctBC_parallel_v3.py
3.  Generate LARRY whitelist using 02_Create_LARRY_WL.py (next step) to be used in 03_correctBC_parallel_v3.py.

``` bash
# On BioHPC, load python module with conda
module load python/3.10.x-anaconda

# COMMAND GROUP 1 - navigate to the working dir
cd /project/pathology/SiZhang_lab/shared/Active_Projects/Ova_LARRY/RPI/Z/L1  

# COMMAND GROUP 2 - activate conda environment that installed all essential python packages
conda activate ISS 

# COMMAND GROUP 3
bash 01_DirectLARRY_extract_L1.sh
```

Step 2. [02_Create_LARRY_WL](/Code/02_Create_LARRY_WL.py): This python script take the output "filtered_LARRY.txt" from step 1 and generate a predicted true LARRY BC whitelist using kneeplot function. It will generate the LARRY_WL.txt and LARRY_freq.txt. Set sensitivity 1 will give fewer BC than set at 6. LARRY_WL.txt will be used for the next BC correction step.

``` bash
python 02_Create_LARRY_WL.py --input_file filtered_LARRY_only.txt --output_file LARRY_WL.txt --freq_output_file LARRY_freq.txt --sensitivity 6
```

-   Step 2.1 [02.1_process_barcodes](/Code/02.1_process_barcodes.py): LARRY barcodes in the LARRY_WL.txt might have a very smally hamming distance. That could due to overamplify the errous/mutatated BCs during the PCR process. We can check the whether are similar BC in the whitelist (huammming distance \< 5) will be subseted, then collapse those BC through [Agglomerative Clustering](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html) before adding back to the subtracted WL. This progress will ensure all the BCs in the final LARRY_WL.txt have a hamming distance bigger than 6.

``` bash
python 02.1_process_barcodes.py LARRY_WL.txt 6 output_subtracted output_subseted final_LARRY_WL.txt
```

-   Step 2.2 [02.2_Generate_CellBC_WL_L1.R](/Code/02.2_Generate_CellBC_WL_L1.R) and [02.2_Generate_CellBC_WL_L2.R](/Code/02.2_Generate_CellBC_WL_L2.R): The goal of this step is generate a cell BC whitelist passed Seurat QC and identified as HTO singlet. The Cell_WL.txt will be used in the Step 3.

Step 3 [03_correctBC_parallel](/Code/03_correctBC_parallel_v3.py): This is a python script used to correct sequencing errors. All the extracted reads will be corrected against cell BC whitelist, and LARRY BC whiltelist. The following python script will correct reads in give column in your input file. In our case, columne 0 = Cell BC; column 1 = UMI; Column 2 is Lib_ID. collumn 3 is LARRY BC. Set hamming dist as 2 means only allow one bit differences. The script will exclude N in hamming dist calculation. The num_tree setting is an estimated number. The higher number will increase the accuracy, but take longer to process. It is balance. The good starting point is the [number of BC in WL]/100. For instance, for 10X run with 10000 CellBC, set --num_trees 100. We run cell BC correction, LARRY BC correction and Lib_ID correct in three different rounds. The intermediate data allows easy tweaking hamming dist settings combinations. e.g c2l4, c3l5. Based on our experience c2-3 and l3-4 are good starting point. **NOTE** this script parallel computing with 40 cores. Use BioPHC 256GB or 512GB nodes.

``` bash
# COMMAND GROUP 5 - correct cell BC against cellBC_WL.txt.  
python 03_correctBC_parallel_v3.py --input_file extracted_cellBC_UMI_LibIDs_LARRY_filtered.txt --column_index 0 --corrected_file c_cell_c2_N.txt --uncorrected_file uc_cell_c2_N.txt --max_distance 2 --whitelist_file L1_CellBC_WL.txt --num_trees 100

# COMMAND GROUP 6 - correct LARRY BC against final_L1_L2_LARRY_WL. Adjust tree based actually number of LARRY BC in the WL. 
python 03_correctBC_parallel_v3.py --input_file c_cell_c2_N.txt --column_index 3 --corrected_file c_post_larry_c2l4_N.txt --uncorrected_file uc_post_larry_c2l4_N.txt --max_distance 4 --whitelist_file final_L1_L2_LARRY_WL --num_trees 20
```

-   Step 3.1 [optional - correct_Lib_ID](/Code/03.1_correct_LibID.py): if we have additional BC information, e.g. Lib batch ID, we can correct potential error using this script by taking the output from Cell and LARRY corrected data. In our case the Lib_ID WL is a 6 know Lib-ID sequences expected from R1. Replace with the RC sequences or correct BC sequences if the Lib_Id was extracted from R2.

``` bash
python 03.1_correct_LibID.py -i c_post_larry_c2l4_N.txt -w R1_BCID_WL.txt -o c_post_larry_c2b2l4_N.txt
```

Step 4. [Post BC correction QC](/Code/04_Post_correction_matching.py): this python script will analyze the post BC correction matching rate and generate a report. Make sure you have correct WL files.

``` bash
# COMMAND GROUP 7
python 04_Post_correction_matching.py c_post_larry_c2b2l4_N.txt L1_CellBC_WL.txt final_L1_L2_LARRY_WL.txt R1_BCID_WL.txt matching_analysis_c2b2l4_N.csv
```

Step 5. [Generate count matrix](/Code/05_CountUMI_sparseMtx.py): The final step is collapse LARRY BC based on UMI and generate a sparse count table. R1_Lib_ID_file.txt is a WL file contains common name for each ID.

``` bash
[s208205@Nucleus004 L1]$ head R1_Lib_ID_file.txt
R1_BC_ID1       ATCACG
R1_BC_ID2       TTAGGC
R1_BC_ID3       CGATGT
R1_BC_ID4       TGACCA
R1_BC_ID5       GCCAAT
R1_BC_ID6       ACTTGA
```

``` bash
# COMMAND GROUP 8
python 05_CountUMI_sparseMtx.py c_post_larry_c2b2l4_N.txt c_post_larry_c2b2l4_N R1_Lib_ID_file.txt 
```

## 3. MetTag LARRY BC assignment for each cell and data integration in Seurat

We used cellranger count to count transcriptome and CITE(HTO).

For cellranger output with HTO run, the outputs are here: [UTSW_CITE_RAW/R02_EA/cellranger.outs/R02_EA_L1_LARRYreseq](https://utsw.box.com/s/fgu1hp7oba83g0a0fq3u97b6c0kzrox8) [UTSW_CITE_RAW/R02_EA/cellranger.outs/R02_EA_L2_LARRYreseq](https://utsw.box.com/s/7b3iz3iyza5ofqfztq8pmvjzl0rlw315)

For RNA velocyto, the looms files are: [UTSW_CITE_RAW/R02_EA/cellranger.outs/R02_EA_L1_HTO/outs/velocyto](https://utsw.box.com/s/jyr99nx821dx3i8akev2gkwf6zlzsgwe) [UTSW_CITE_RAW/R02_EA/cellranger.outs/R02_EA_L2_HTO/outs/velocyto](https://utsw.box.com/s/ezs9a6ef9r2ry5bsmhgrt86b994jdzlg)

**Step 6.1** The final output files (sparse matrix) can be loaded a separate "Assay" to the Seurat obj using L1 [LARRY and Lib_ID assignment in R](/Code/06.1_AssignLARRY_L1.R) code and [similar code for R2](/Code/06.1_AssignLARRY_L2.R).

**Step 6.2** Consolidate L1 and L2 using the [R code](/Code/06.2_ConsolidatedMeta_L1_L2.R). The SCT integrated obj is used for downstream analysis "./DATA/RDS/MetTag.Ova_merged_SCT_with_updated_meta.rds"

## 4. R object, Figures, and DATA/RDS folder

Github can not hold big file. Therefore, it mainly serves as a place to hold code and experimental information. We store large data/RDS file on Box:

***RDS:***

[Box-Box/S.Zhang_Lab/UTSW_DATA/R02_EA/MetTag_BC_OVA/DATA/RDS](https://utsw.box.com/s/0uw4x1zb97rfb8pgnkidg92edqs1qu05)

***Looms files:***

[Box-Box/S.Zhang_Lab/UTSW_DATA/R02_EA/MetTag_BC_OVA/DATA/Looms](https://utsw.box.com/s/vlnptj7rfvhor0pdsv9nkc5skrhfutvu)

***Velocity (CellRank2) analysis Jupyter Notebook:***

[/Users/S208205/Library/CloudStorage/Box-Box/S.Zhang_Lab/UTSW_DATA/R02_EA/MetTag_BC_OVA/DATA/Looms/Mets_CellRank2.ipynb](/Users/S208205/Library/CloudStorage/Box-Box/S.Zhang_Lab/UTSW_DATA/R02_EA/MetTag_BC_OVA/DATA/Looms/Mets_CellRank2.ipynb)
